
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs — Neuromatch Academy: Deep Learning</title>
<link href="../../../_static/css/theme.css" rel="stylesheet"/>
<link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
<script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.jpg" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W2D5_Tutorial3.html" rel="next" title="Tutorial 3: Conditional GANs and Implications of GAN Technology"/>
<link href="W2D5_Tutorial1.html" rel="prev" title="Tutorial 1: Variational Autoencoders (VAEs)"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.jpg"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main navigation" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
   Introduction
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  The Basics
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/further_reading.html">
     Suggested further reading (TBD)
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_Optimization/chapter_title.html">
   Optimization (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_Optimization/student/W1D4_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_Regularization/chapter_title.html">
   Regularization (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Doing more with fewer parameters
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/chapter_title.html">
   Convnets And Recurrent Neural Networks (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial2.html">
     Tutorial 2: Training loop of CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial3.html">
     Tutorial 3: Introduction to RNNs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ModernConvnets/student/W2D2_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/chapter_title.html">
   Modern Recurrent Neural Networks (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial1.html">
     Tutorial 1: Modeling sequencies and encoding text
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial2.html">
     Tutorial 2: Modern RNNs and their variants
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/student/W2D4_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Generative Models (W2D5)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W2D5_Tutorial1.html">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W2D5_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<div class="dropdown-buttons-trigger">
<button aria-label="Download this page" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fas fa-download"></i></button>
<div class="dropdown-buttons">
<!-- ipynb file if we had a myst markdown file -->
<!-- Download raw file -->
<a class="dropdown-buttons" href="../../../_sources/tutorials/W2D5_GenerativeModels/student/W2D5_Tutorial2.ipynb"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Download source file" type="button">.ipynb</button></a>
<!-- Download PDF via print -->
<button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" id="download-print" onclick="window.print()" title="Print to PDF" type="button">.pdf</button>
</div>
</div>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/NeuromatchAcademy/course-content-dl"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W2D5_GenerativeModels/student/W2D5_Tutorial2.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
     Tutorial Objectives
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-how-to-train-gans">
   Section 1: How to train GANs.
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-generative-adversarial-networks">
     Video 1: Generative Adversarial Networks
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-the-gan-training-loop">
     Coding Exercise 1: The GAN training loop
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-the-difficulty-of-gan-training">
   Section 2: The difficulty of GAN training.
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-failure-modes-of-gan-training">
     Interactive Demo 2: Failure modes of GAN training
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#gan-training-demo">
       GAN training demo
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-2-what-makes-gans-hard-to-train">
     Exercise 2: What makes GANs hard to train?
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-gan-training-objective">
   Section 3: GAN Training Objective
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-principles-of-gans">
     Video 2: Principles of GANs
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-discriminator-loss">
     Section 3.1:  Discriminator Loss
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-1-implement-discriminator-loss">
       Coding Exercise 3.1: Implement Discriminator Loss
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-density-ratio-estimation-and-the-optimal-discriminator">
     Section 3.2:  Density ratio estimation and the optimal discriminator
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-2-estimating-the-density-ratio-by-the-discriminator">
       Coding Exercise 3.2: Estimating the density ratio by the discriminator
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-3-the-generator-loss">
     Section 3.3:  The generator loss
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-3-the-generator-loss">
       Coding Exercise 3.3: The generator loss
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-gan-training-in-action">
   Section 4: GAN training in action!
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-4-gan-training-in-action">
     Interactive Demo 4: GAN training in action
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#gan-demo">
       GAN demo
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D5_GenerativeModels/student/W2D5_Tutorial2.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<div class="section" id="tutorial-2-introduction-to-gans-and-density-ratio-estimation-perspective-of-gans">
<h1>Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs<a class="headerlink" href="#tutorial-2-introduction-to-gans-and-density-ratio-estimation-perspective-of-gans" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 2, Day 5: Generative Models</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Kai Xu, Seungwook Han, Akash Srivastava</p>
<p><strong>Content reviewers:</strong> Polina Turishcheva, Melvin Selim Atay, Hadi Vafaei, Deepak Raya</p>
<p><strong>Content editors:</strong> Spiros Chavlis</p>
<p><strong>Production editors:</strong> Arush Tagade, Spiros Chavlis</p>
<p><strong>Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs</strong></p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p><hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h2>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h2>
<p>The goal of this tutorial is two-fold; first you will be introduced to GANs training, and you will be able to understand how GANs are connected to other generative models that we have been before.</p>
<p>By the end of the first part of this tutorial you will be able to:</p>
<ul class="simple">
<li><p>Understand, at a high level, how GANs are implemented.</p></li>
<li><p>Understand the training dynamics of GANs.</p></li>
<li><p>Know about a few failure modes of GAN training.</p></li>
<li><p>Understand density ratio estimation using a binary classifier</p></li>
<li><p>Understand the connection between GANs and other generative models.</p></li>
<li><p>Implement a GAN.</p></li>
</ul>
<p>Tutorial slides</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Tutorial slides</span>
<span class="c1"># you should link the slides for all tutorial videos here (we will store pdfs on osf)</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="n">HTML</span><span class="p">(</span><span class="s1">'&lt;iframe src="https://mfr.ca-1.osf.io/render?url=https://osf.io/dftym/?direct%26mode=render</span><span class="si">%26a</span><span class="s1">ction=download%26mode=render" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"&gt;&lt;/iframe&gt;'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># interactive display</span>
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="o">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s1">'retina'</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Plotting functions</span>

<span class="n">ld_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">7.0066e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.6368e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4250e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0247e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1795e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">4.5558e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.1316e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0932e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.8608e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.5838e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.0530e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.1201e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.8020e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7787e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2246e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">6.5677e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.6001e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2313e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8262e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2649e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.8330e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.8619e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.2357e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3450e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.6891e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">5.9257e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.8415e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.3197e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6862e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.8506e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.1871e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.0422e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7378e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3099e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8926e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.4508e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5696e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.2787e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2420e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.9795e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">6.4189e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4120e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.3684e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4066e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9753e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.4178e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0399e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3173e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2792e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.2990e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.9872e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.9378e-03</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.5890e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.6643e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8003e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.5818e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.2227e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1862e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8743e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4200e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.1988e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.5513e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5905e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.2916e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.5556e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">8.2807e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.5568e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.8475e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1049e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0104e-02</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">2.1655e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1496e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.6168e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.9624e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.7098e-02</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">6.0623e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.1165e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.7302e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.0514e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6756e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.3807e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.7368e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2763e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.6959e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.2157e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">8.7762e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.7295e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3052e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.6777e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5904e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.8083e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.8388e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5323e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.7549e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.2722e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.7393e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.8814e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0310e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2077e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5507e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">6.8569e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4620e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.2639e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4160e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.6734e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.0053e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.7353e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2676e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.0812e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0005e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">4.2908e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.1369e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2579e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8496e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4798e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">7.3089e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1962e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6095e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7558e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.3166e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.1445e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4674e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0600e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0727e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.4371e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">8.0499e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.0521e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.6835e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0485e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.6747e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.6399e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.6883e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9348e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.1448e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6332e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.2233e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3336e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.6564e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2841e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3561e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">7.4717e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.7926e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.7849e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.3715e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4933e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">2.7738e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6899e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5758e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2608e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.5770e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.7136e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.8316e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1988e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.3828e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8033e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">2.3017e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.9936e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1917e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6659e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.7669e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.2955e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2076e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2793e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0528e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4894e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">5.7428e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.3208e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.5673e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6617e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.9169e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.2182e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.8092e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1924e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4566e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.7350e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">2.8332e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.1506e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.7432e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.8965e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0727e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.4615e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.8868e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1218e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2368e-03</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.0038e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">5.3746e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.4080e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.1625e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1786e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2797e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.1498e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3978e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9515e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1614e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.1456e-03</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.9316e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3849e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.2799e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1649e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3837e-01</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">plotting_ld</span><span class="p">(</span><span class="n">ld</span><span class="p">,</span> <span class="n">true</span><span class="o">=</span><span class="n">ld_true</span><span class="p">):</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Ground Truth"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">ld</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">"x"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s2">"Your implementation"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Loss from oracle implementation"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Loss from your implementation"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Discriminator Loss"</span><span class="p">)</span>


<span class="n">lg_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">7.0066e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.6368e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4250e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0247e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1795e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">4.5558e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.1316e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0932e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.8608e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.5838e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.0530e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.1201e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.8020e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7787e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2246e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">6.5677e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.6001e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2313e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8262e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2649e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.8330e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.8619e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.2357e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3450e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.6891e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">5.9257e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.8415e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.3197e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6862e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.8506e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.1871e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.0422e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7378e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3099e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8926e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.4508e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5696e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.2787e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2420e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.9795e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">6.4189e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4120e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.3684e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4066e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9753e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.4178e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0399e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3173e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2792e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.2990e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.9872e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.9378e-03</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.5890e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.6643e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8003e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.5818e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.2227e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1862e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.8743e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4200e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.1988e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.5513e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5905e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.2916e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.5556e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">8.2807e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.5568e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.8475e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1049e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0104e-02</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">2.1655e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1496e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.6168e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.9624e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.7098e-02</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">6.0623e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.1165e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.7302e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.0514e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6756e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.3807e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.7368e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2763e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.6959e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.2157e-01</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">8.7762e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.7295e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3052e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.6777e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5904e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">3.8083e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.8388e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5323e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.7549e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.2722e+00</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.7393e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.8814e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0310e-01</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2077e+00</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5507e+00</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">plotting_lg</span><span class="p">(</span><span class="n">lg</span><span class="p">,</span> <span class="n">true</span><span class="o">=</span><span class="n">lg_true</span><span class="p">):</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Ground Truth"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">lg</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">"x"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s2">"Your implementation"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Loss from oracle implementation"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Loss from your implementation"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Generator loss"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plotting_ratio_impl</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">x_real</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">yscale</span><span class="o">=</span><span class="s2">"linear"</span><span class="p">):</span>
  <span class="n">dist_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">normal</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">dist_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">normal</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">prob_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">dist_p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
  <span class="n">prob_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">dist_q</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
  <span class="n">trueRatio</span> <span class="o">=</span> <span class="n">prob_p</span> <span class="o">/</span> <span class="n">prob_q</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trueRatio</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"True tatio"</span><span class="p">)</span>

  <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x_real</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">][::</span><span class="mi">10</span><span class="p">],</span> <span class="n">ratio</span><span class="p">[:,</span><span class="mi">0</span><span class="p">][::</span><span class="mi">10</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">"x"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s2">"Ratio from discriminator"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x_real</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">"step"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Real"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x_fake</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s2">"step"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Fake"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="n">yscale</span><span class="p">)</span>
  <span class="n">title</span> <span class="o">=</span> <span class="s2">"Densities and the ratio from discriminator"</span>
  <span class="k">if</span> <span class="n">yscale</span> <span class="o">==</span> <span class="s2">"log"</span><span class="p">:</span>
    <span class="n">title</span> <span class="o">+=</span> <span class="s2">" in log scale"</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plotting_ratio</span><span class="p">(</span><span class="n">x_real</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">,</span> <span class="n">ratio</span><span class="p">):</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
  <span class="n">plotting_ratio_impl</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_real</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">yscale</span><span class="o">=</span><span class="s2">"linear"</span><span class="p">)</span>
  <span class="n">plotting_ratio_impl</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x_real</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">yscale</span><span class="o">=</span><span class="s2">"log"</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Interactive</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">display_widgets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">widget</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">widgets</span><span class="p">:</span>
      <span class="n">display</span><span class="p">(</span><span class="n">widget</span><span class="p">)</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">widgets</span><span class="p">,</span> <span class="n">handler</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">handler_with_extra_steps</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
      <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">handler</span><span class="p">(</span><span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">w</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">widgets</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">display_widgets</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">widgets</span> <span class="o">=</span> <span class="n">widgets</span>
    <span class="k">for</span> <span class="n">widget</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">widgets</span><span class="p">:</span>
      <span class="n">widget</span><span class="o">.</span><span class="n">observe</span><span class="p">(</span><span class="n">handler_with_extra_steps</span><span class="p">,</span>
                     <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">'value'</span><span class="p">])</span>
    <span class="n">handler</span><span class="p">(</span><span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">w</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">widgets</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">display_widgets</span><span class="p">()</span>


<span class="c1"># Using Interactive</span>
<span class="c1"># All widgets: https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html</span>


<span class="k">def</span> <span class="nf">make_plot</span><span class="p">(</span><span class="n">xmax</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">ftype</span><span class="p">):</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ftype</span> <span class="o">==</span> <span class="s2">"sin"</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ftype</span> <span class="o">==</span> <span class="s2">"cos"</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ftype</span> <span class="o">==</span> <span class="s2">"tanh"</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.1</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">title</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Range from -1 to </span><span class="si">{</span><span class="n">xmax</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">fig</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline">¶</a></h2>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Set random seed</span>

<span class="c1">#@markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># for DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.'</span><span class="p">)</span>


<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h2>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>

<span class="c1"># inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"WARNING: For this notebook to perform best, "</span>
        <span class="s2">"if possible, in the menu under `Runtime` -&gt; "</span>
        <span class="s2">"`Change runtime type.`  select `GPU` "</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook."</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-how-to-train-gans">
<h1>Section 1: How to train GANs.<a class="headerlink" href="#section-1-how-to-train-gans" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-1-generative-adversarial-networks">
<h2>Video 1: Generative Adversarial Networks<a class="headerlink" href="#video-1-generative-adversarial-networks" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>GANs consist two networks: A critic or discriminator (<code class="docutils literal notranslate"><span class="pre">disc</span></code>) and a generator (<code class="docutils literal notranslate"><span class="pre">gen</span></code>) that are trained by alternating between the following two steps:</p>
<ul class="simple">
<li><p>In step 1, we update the parameters (<code class="docutils literal notranslate"><span class="pre">disc.params</span></code>) of the discriminator by backpropagating through the discriminator loss (BCE loss) <code class="docutils literal notranslate"><span class="pre">disc.loss</span></code>.</p></li>
<li><p>In step 2, we update the parameters (<code class="docutils literal notranslate"><span class="pre">gen.params</span></code>) of the generator by backpropagating through the generator loss, <code class="docutils literal notranslate"><span class="pre">gen.loss</span></code> (-1 * BCE loss).</p></li>
</ul>
<p>We will now implement a simple GAN training loop!</p>
</div>
<div class="section" id="coding-exercise-1-the-gan-training-loop">
<h2>Coding Exercise 1: The GAN training loop<a class="headerlink" href="#coding-exercise-1-the-gan-training-loop" title="Permalink to this headline">¶</a></h2>
<p>To get you started we have implemented a simple GAN in pseudocode. All you have to do is to implement the training loop.</p>
<p><strong>Your goal</strong> is to arrange the functions given below in the correct order in the <code class="docutils literal notranslate"><span class="pre">train_gan_iter</span></code> function</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">disc.loss(x_real,</span> <span class="pre">x_fake)</span></code>: Discriminator loss</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">disc.classify(x)</span></code>: Classify <code class="docutils literal notranslate"><span class="pre">x</span></code> as real or fake</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gen.loss(x_fake,</span> <span class="pre">disc_fn)</span></code>: Generator loss</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">disc_fn(x)</span></code> is a function to check <code class="docutils literal notranslate"><span class="pre">x</span></code> is real or fake.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gen.sample(num_samples)</span></code>: Generate samples from the generator</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">backprop(loss,</span> <span class="pre">model)</span></code>: Compute gradient of <code class="docutils literal notranslate"><span class="pre">loss</span></code> wrt <code class="docutils literal notranslate"><span class="pre">model</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code> is either <code class="docutils literal notranslate"><span class="pre">disc</span></code> or <code class="docutils literal notranslate"><span class="pre">gen</span></code></p></li>
</ul>
<p>We have already taken care of most of these functions. So you only have to figure out the placement of <code class="docutils literal notranslate"><span class="pre">disc.loss</span></code> and <code class="docutils literal notranslate"><span class="pre">gen.loss</span></code> functions.</p>
<p><strong>We highly recommend studying <code class="docutils literal notranslate"><span class="pre">train_gan_iter</span></code> function to understand how the GAN training loop is structured.</strong></p>
<p><em>Execute this cell to enable helper functions</em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Execute this cell to enable helper functions*</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">():</span>
  <span class="k">return</span> <span class="s2">"get_data"</span>


<span class="k">class</span> <span class="nc">Disc</span><span class="p">:</span>

  <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_real</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">x_real</span> <span class="o">==</span> <span class="s2">"get_data"</span> <span class="ow">and</span> <span class="n">x_fake</span> <span class="o">==</span> <span class="s2">"gen.sample"</span><span class="p">,</span><span class="s2">"Inputs to disc.loss is wrong"</span>

  <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="s2">"disc.classify"</span>


<span class="k">class</span> <span class="nc">Gen</span><span class="p">:</span>

  <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">,</span> <span class="n">disc_fn</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">x_fake</span> <span class="o">==</span> <span class="s2">"gen.sample"</span> <span class="ow">and</span> <span class="n">disc_fn</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="s2">"disc.classify"</span><span class="p">,</span> <span class="s2">"Inputs to gen.loss is wrong"</span>

  <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
    <span class="k">return</span> <span class="s2">"gen.sample"</span>


<span class="k">def</span> <span class="nf">backprop</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
  <span class="k">pass</span>


<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
  <span class="k">pass</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_gan_iter</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
  <span class="sd">"""Update the discriminator (`disc`) and the generator (`gen`) using `data`</span>

<span class="sd">  Args:</span>
<span class="sd">    data (ndarray): An array of shape (N,) that contains the data</span>
<span class="sd">    disc (Disc): The discriminator</span>
<span class="sd">    gen (Gen): The generator</span>

<span class="sd">  Returns:</span>
<span class="sd">  """</span>
  <span class="c1">#################################################</span>
  <span class="c1"># Intructions for students:                        #</span>
  <span class="c1"># Fill out ... in the function and remove below #</span>
  <span class="c1">#################################################</span>

  <span class="c1"># Number of samples in the data batch</span>
  <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">200</span>

  <span class="c1"># The data is the real samples</span>
  <span class="n">x_real</span> <span class="o">=</span> <span class="n">data</span>

  <span class="c1">## Discriminator training</span>

  <span class="c1"># Ask the generator to generate some fake samples</span>
  <span class="n">x_fake</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>

  <span class="c1">#################################################</span>
  <span class="c1">## TODO for students: details of what they should do ##</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: Write code to compute disc_loss"</span><span class="p">)</span>
  <span class="c1">#################################################</span>
  <span class="c1"># Compute the discriminator loss</span>
  <span class="n">disc_loss</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># Compute the gradient for discriminator</span>
  <span class="n">disc_grad</span> <span class="o">=</span> <span class="n">backprop</span><span class="p">(</span><span class="n">disc_loss</span><span class="p">,</span> <span class="n">disc</span><span class="p">)</span>

  <span class="c1"># Update the discriminator</span>
  <span class="n">update</span><span class="p">(</span><span class="n">disc</span><span class="p">,</span> <span class="n">disc_grad</span><span class="p">)</span>

  <span class="c1">## Generator training</span>

  <span class="c1"># Ask the generator to generate some fake samples</span>
  <span class="n">x_fake</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>

  <span class="c1">#################################################</span>
  <span class="c1">## TODO for students: details of what they should do ##</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: Write code to compute gen_loss"</span><span class="p">)</span>
  <span class="c1">#################################################</span>
  <span class="c1"># Compute the generator loss</span>
  <span class="n">gen_loss</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># Compute the gradient for generator</span>
  <span class="n">gen_grad</span> <span class="o">=</span> <span class="n">backprop</span><span class="p">(</span><span class="n">gen_loss</span><span class="p">,</span> <span class="n">gen</span><span class="p">)</span>

  <span class="c1"># Update the generator</span>
  <span class="n">update</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">gen_grad</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s2">"Your implementation passes the check!"</span><span class="p">)</span>


<span class="n">data</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>
<span class="n">disc</span> <span class="o">=</span> <span class="n">Disc</span><span class="p">()</span>
<span class="n">gen</span> <span class="o">=</span> <span class="n">Gen</span><span class="p">()</span>
<span class="c1">## Uncomment below to check your function</span>
<span class="c1"># train_gan_iter(data, disc, gen)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_GenerativeModels/solutions/W2D5_Tutorial2_Solution_dc5b38a9.py"><em>Click for solution</em></a></p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-the-difficulty-of-gan-training">
<h1>Section 2: The difficulty of GAN training.<a class="headerlink" href="#section-2-the-difficulty-of-gan-training" title="Permalink to this headline">¶</a></h1>
<p>In this section we will develop an intuition for the training dynamics of GANs.</p>
<div class="section" id="interactive-demo-2-failure-modes-of-gan-training">
<h2>Interactive Demo 2: Failure modes of GAN training<a class="headerlink" href="#interactive-demo-2-failure-modes-of-gan-training" title="Permalink to this headline">¶</a></h2>
<p>GAN training is notoriously difficult because
it is very sensitive to hyper-parameters such as learning rate and model architecture. To help you develop a sense of this, here is a very simple GAN training demo that we have borrowed from Andrej Karpathy’s website.</p>
<p>Even though the GAN in this demo is very simple and operates in either 1D or 2D spaces, it is however very sensitive to the learning rate. Try it for yourself!</p>
<div class="section" id="gan-training-demo">
<h3>GAN training demo<a class="headerlink" href="#gan-training-demo" title="Permalink to this headline">¶</a></h3>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
<div class="section" id="exercise-2-what-makes-gans-hard-to-train">
<h2>Exercise 2: What makes GANs hard to train?<a class="headerlink" href="#exercise-2-what-makes-gans-hard-to-train" title="Permalink to this headline">¶</a></h2>
<p>You have played with the demo and it’s time to think about a few questions</p>
<ol class="simple">
<li><p>Which target is more stable to train, 1D or 2D?</p></li>
<li><p>If you keep increasing the learning rate, what happens? Does it happen in both the cases, i.e., 1D/2D targets?</p></li>
<li><p>Can you think of some drawbacks of using small learning rates?</p></li>
</ol>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_GenerativeModels/solutions/W2D5_Tutorial2_Solution_8febc070.py"><em>Click for solution</em></a></p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-gan-training-objective">
<h1>Section 3: GAN Training Objective<a class="headerlink" href="#section-3-gan-training-objective" title="Permalink to this headline">¶</a></h1>
<p>The training objective of GANs consists of the losses for generators and discriminators respectively. In this section we will be implementing these objectives.</p>
<div class="section" id="video-2-principles-of-gans">
<h2>Video 2: Principles of GANs<a class="headerlink" href="#video-2-principles-of-gans" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
<div class="section" id="section-3-1-discriminator-loss">
<h2>Section 3.1:  Discriminator Loss<a class="headerlink" href="#section-3-1-discriminator-loss" title="Permalink to this headline">¶</a></h2>
<p>The critic or the discriminator in a vanilla GAN is trained as a binary classifier using the BCE criteria. In this section, we will implement the training objective for the discriminator.</p>
<div class="math notranslate nohighlight">
\[\text{BCE}_\omega = \mathbb{E}_{x \sim p}[\log(\sigma(D_\omega(x)))] + \mathbb{E}_{x \sim q}[\log(1 - \sigma(D_\omega(x)))]\]</div>
<p>Here, <span class="math notranslate nohighlight">\(p\)</span> is the data distribution and <span class="math notranslate nohighlight">\(q\)</span> is the generator distribution. <span class="math notranslate nohighlight">\(D_\omega\)</span> is the logit, which represents <span class="math notranslate nohighlight">\(\log \frac{p}{q}\)</span>. <span class="math notranslate nohighlight">\(\sigma\)</span> is the sigmoid function and therfore, <span class="math notranslate nohighlight">\(\sigma(D_\omega)\)</span> represents <span class="math notranslate nohighlight">\(\frac{p}{p+q}\)</span>.</p>
<div class="section" id="coding-exercise-3-1-implement-discriminator-loss">
<h3>Coding Exercise 3.1: Implement Discriminator Loss<a class="headerlink" href="#coding-exercise-3-1-implement-discriminator-loss" title="Permalink to this headline">¶</a></h3>
<p>To get you started we have implemented a simple GAN in pseudocode and partially implemented the discriminator training objective.</p>
<p><strong>Your goal</strong> is to complete the missing part in the training objective of the discriminator in the function <code class="docutils literal notranslate"><span class="pre">loss_disc</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">loss_disc</span></code> also allows you evaluate the loss function on some random samples.
If your implementation is correct, you will see a plot where the loss values from your implementation will match the ground truth loss values.</p>
<p>In practice, given <span class="math notranslate nohighlight">\(N\)</span> samples, we estimate BCE as
$<span class="math notranslate nohighlight">\(\text{BCE}_\omega = -\frac{1}{N} \sum_{i=1}^N y_i \log(\sigma(D_\omega(x_i)) + (1-y_i) \log(1-\sigma(D_\omega(x_i))).\)</span><span class="math notranslate nohighlight">\(
Here, \)</span>y<span class="math notranslate nohighlight">\( is the label. \)</span>y=1<span class="math notranslate nohighlight">\( when \)</span>x \sim p<span class="math notranslate nohighlight">\( (real data) and \)</span>y=0<span class="math notranslate nohighlight">\( when \)</span>x \sim q$ (fake data).</p>
<p>Please note, <code class="docutils literal notranslate"><span class="pre">disc.classify</span></code> = <span class="math notranslate nohighlight">\(\sigma(D_\omega)\)</span> in <code class="docutils literal notranslate"><span class="pre">loss_disc</span></code>.</p>
<p><em>Execute this cell to enable helper functions</em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Execute this cell to enable helper functions*</span>


<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
  <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="n">num_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>


<span class="k">class</span> <span class="nc">DummyGen</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="n">num_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mi">2</span>


<span class="k">class</span> <span class="nc">DummyDisc</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">loss_disc</span><span class="p">(</span><span class="n">disc</span><span class="p">,</span> <span class="n">x_real</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">):</span>
  <span class="sd">"""Compute the discriminator loss for `x_real` and `x_fake` given `disc`</span>

<span class="sd">  Args:</span>
<span class="sd">    disc: The discriminator</span>
<span class="sd">    x_real (ndarray): An array of shape (N,) that contains the real samples</span>
<span class="sd">    x_fake (ndarray): An array of shape (N,) that contains the fake samples</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray: The discriminator loss</span>
<span class="sd">  """</span>

  <span class="n">label_real</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="c1">#################################################</span>
  <span class="c1"># TODO for students: Loss for real data</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: Implement loss for real samples"</span><span class="p">)</span>
  <span class="c1">#################################################</span>
  <span class="n">loss_real</span> <span class="o">=</span> <span class="n">label_real</span> <span class="o">*</span> <span class="o">...</span>

  <span class="n">label_fake</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="c1">#################################################</span>
  <span class="c1"># TODO for students: Loss for fake data</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: Implement loss for fake samples"</span><span class="p">)</span>
  <span class="c1">#################################################</span>
  <span class="n">loss_fake</span> <span class="o">=</span> <span class="o">...</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">disc</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">x_fake</span><span class="p">))</span>


  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">loss_real</span><span class="p">,</span> <span class="n">loss_fake</span><span class="p">])</span>


<span class="n">disc</span> <span class="o">=</span> <span class="n">DummyDisc</span><span class="p">()</span>
<span class="n">gen</span> <span class="o">=</span> <span class="n">DummyGen</span><span class="p">()</span>

<span class="n">x_real</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>
<span class="n">x_fake</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

<span class="c1">## Uncomment to check your function</span>
<span class="c1"># ld = loss_disc(disc, x_real, x_fake)</span>
<span class="c1"># plotting_ld(ld)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_GenerativeModels/solutions/W2D5_Tutorial2_Solution_393f89f3.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial2_Solution_393f89f3_1.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial2_Solution_393f89f3_1.png" style="width: 971.0px; height: 971.0px;"/></a>
<p><strong>A note on numerical stability</strong></p>
<p>It is common that functions like <span class="math notranslate nohighlight">\(\log\)</span> throw a numerical error.
For <span class="math notranslate nohighlight">\(\log\)</span>, it happens when <span class="math notranslate nohighlight">\(x\)</span> in <span class="math notranslate nohighlight">\(\log(x)\)</span> is very close to 0.
The most common practice is to always add some very small value <span class="math notranslate nohighlight">\(\epsilon\)</span> to <span class="math notranslate nohighlight">\(x\)</span>, i.e. use <span class="math notranslate nohighlight">\(\log(x + \epsilon)\)</span> instead.
Most build-in functions in modern DL frameworks like TensorFlow or PyTorch handle such things in their build-in loss already, e.g. <code class="docutils literal notranslate"><span class="pre">torch.nn.BCE</span></code>, which is equivalent to the loss you implemented above.</p>
</div>
</div>
<div class="section" id="section-3-2-density-ratio-estimation-and-the-optimal-discriminator">
<h2>Section 3.2:  Density ratio estimation and the optimal discriminator<a class="headerlink" href="#section-3-2-density-ratio-estimation-and-the-optimal-discriminator" title="Permalink to this headline">¶</a></h2>
<p>As explained in the lecture, the critic in GAN that trains as a binary classifier, upon training becomes a <em>density ratio estimator</em> of <span class="math notranslate nohighlight">\(\frac{p}{q}\)</span>.</p>
<p>The estimated density ratio allows for quantifying how far the real and generator distributions are from each other using <span class="math notranslate nohighlight">\(f\)</span>-divergence. The generator minimizes this estimated <span class="math notranslate nohighlight">\(f\)</span>-divergence during training.</p>
<p>We will now train a discriminator to see how it estimates the density ratio between two distributions.</p>
<div class="section" id="coding-exercise-3-2-estimating-the-density-ratio-by-the-discriminator">
<h3>Coding Exercise 3.2: Estimating the density ratio by the discriminator<a class="headerlink" href="#coding-exercise-3-2-estimating-the-density-ratio-by-the-discriminator" title="Permalink to this headline">¶</a></h3>
<p>We have provided an implementation of a binary critic in the class <code class="docutils literal notranslate"><span class="pre">OptimalDisc</span></code>.</p>
<p><strong>Your goal</strong> is to complete the implementation of the function <code class="docutils literal notranslate"><span class="pre">ratio_disc</span></code> below using the function <code class="docutils literal notranslate"><span class="pre">classify</span></code> from <code class="docutils literal notranslate"><span class="pre">OptimalCritic</span></code> class.</p>
<p>Upon correct implementation, you should see that the plot of the ratios from the optimal discriminator align to the true density ratio.</p>
<p><strong>Remember, <span class="math notranslate nohighlight">\(\frac{p}{p + q} = \sigma(D_\omega(x))\)</span></strong></p>
<p><em>Execute this cell to enable the optimal discriminator: <code class="docutils literal notranslate"><span class="pre">OptimalDisc</span></code></em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Execute this cell to enable the optimal discriminator: `OptimalDisc`*</span>

<span class="k">class</span> <span class="nc">OptimalDisc</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">dist_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">normal</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">dist_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">normal</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">prob_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">dist_p</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">prob_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">dist_q</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">prob_p</span> <span class="o">/</span> <span class="p">(</span><span class="n">prob_p</span> <span class="o">+</span> <span class="n">prob_q</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ratio_disc</span><span class="p">(</span><span class="n">disc</span><span class="p">,</span> <span class="n">x_real</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">):</span>
  <span class="sd">"""Compute the density ratio between real distribution and fake distribution for `x`</span>

<span class="sd">  Args:</span>
<span class="sd">    disc: The discriminator</span>
<span class="sd">    x (ndarray): An array of shape (N,) that contains the samples to evaluate</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray: The density ratios</span>
<span class="sd">  """</span>

  <span class="c1"># Put samples together</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x_real</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">])</span>

  <span class="c1">#################################################</span>
  <span class="c1"># TODO for students: Compute p / (p + q) i.e. p(D=1|x)</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: Implement p_over_pplusq"</span><span class="p">)</span>
  <span class="c1">#################################################</span>
  <span class="n">p_over_pplusq</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1">#################################################</span>
  <span class="c1"># TODO for students: Compute q / (p + q) i.e. 1 - p(D=1|x)</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: Implement q_over_pplusq"</span><span class="p">)</span>
  <span class="c1">#################################################</span>
  <span class="n">q_over_pplusq</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># Compute p / q</span>
  <span class="n">p_over_q</span> <span class="o">=</span> <span class="n">p_over_pplusq</span> <span class="o">/</span> <span class="n">q_over_pplusq</span>

  <span class="k">return</span> <span class="n">p_over_q</span>


<span class="n">disc</span> <span class="o">=</span> <span class="n">OptimalDisc</span><span class="p">()</span>
<span class="n">gen</span> <span class="o">=</span> <span class="n">DummyGen</span><span class="p">()</span>

<span class="n">x_real</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="mi">1_000</span><span class="p">)</span>
<span class="n">x_fake</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1_000</span><span class="p">)</span>

<span class="c1">## Uncomment below to check your function</span>
<span class="c1"># ratio = ratio_disc(disc, x_real, x_fake)</span>
<span class="c1"># plotting_ratio(x_real, x_fake, ratio)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_GenerativeModels/solutions/W2D5_Tutorial2_Solution_007bde00.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial2_Solution_007bde00_1.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial2_Solution_007bde00_1.png" style="width: 1963.0px; height: 971.0px;"/></a>
</div>
</div>
<div class="section" id="section-3-3-the-generator-loss">
<h2>Section 3.3:  The generator loss<a class="headerlink" href="#section-3-3-the-generator-loss" title="Permalink to this headline">¶</a></h2>
<p>Now that we have a trained critic, lets see how to train the generator using it.</p>
<div class="section" id="coding-exercise-3-3-the-generator-loss">
<h3>Coding Exercise 3.3: The generator loss<a class="headerlink" href="#coding-exercise-3-3-the-generator-loss" title="Permalink to this headline">¶</a></h3>
<p>We will now implement the generator loss function and evaluate it on some fixed points.</p>
<p><strong>Your goal</strong> is to complete the implementation of the function <code class="docutils literal notranslate"><span class="pre">loss_gen</span></code> using the optimal critic from above.</p>
<p>Upon correct implementation, you shall see a plot where the loss values from generator samples align with the “Correct” values.</p>
<p><strong>HINT:</strong> You simply need to change the labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">loss_gen</span><span class="p">(</span><span class="n">disc</span><span class="p">,</span> <span class="n">x_fake</span><span class="p">):</span>
  <span class="sd">"""Compute the generator loss for `x_fake` given `disc`</span>

<span class="sd">  Args:</span>
<span class="sd">    disc: The generator</span>
<span class="sd">    x_fake (ndarray): An array of shape (N,) that contains the fake samples</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray: The generator loss</span>
<span class="sd">  """</span>

  <span class="c1">#################################################</span>
  <span class="c1"># TODO for students: Loss for fake data</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: Implement loss for fake data"</span><span class="p">)</span>
  <span class="c1">#################################################</span>
  <span class="n">label_fake</span> <span class="o">=</span> <span class="o">...</span>
  <span class="n">loss_fake</span> <span class="o">=</span> <span class="n">label_fake</span> <span class="o">*</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">loss_fake</span>


<span class="n">disc</span> <span class="o">=</span> <span class="n">DummyDisc</span><span class="p">()</span>
<span class="n">gen</span> <span class="o">=</span> <span class="n">DummyGen</span><span class="p">()</span>

<span class="n">x_fake</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="c1">## Uncomment below to check your function</span>
<span class="c1"># lg = loss_gen(disc, x_fake)</span>
<span class="c1"># plotting_lg(lg)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_GenerativeModels/solutions/W2D5_Tutorial2_Solution_04a08f8f.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial2_Solution_04a08f8f_1.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial2_Solution_04a08f8f_1.png" style="width: 971.0px; height: 971.0px;"/></a>
<p><strong>Did you notice?</strong></p>
<p>The loss you implemented for generator is essentially the part for real data in <code class="docutils literal notranslate"><span class="pre">loss_disc</span></code>, i.e. it is saying, “the data I am feeding to you is real and not fake”.</p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-gan-training-in-action">
<h1>Section 4: GAN training in action!<a class="headerlink" href="#section-4-gan-training-in-action" title="Permalink to this headline">¶</a></h1>
<p>In this section we will be playing with a complete implementation of GAN.</p>
<div class="section" id="interactive-demo-4-gan-training-in-action">
<h2>Interactive Demo 4: GAN training in action<a class="headerlink" href="#interactive-demo-4-gan-training-in-action" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Execute this cell to enable the implemented GAN*</span>
<span class="c1"># @markdown</span>
<span class="c1"># @markdown You are encouraged to take a look at the implementation as well.</span>

<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">output_activation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_activation</span> <span class="o">=</span> <span class="n">output_activation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_init_layers</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_init_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">):</span>
    <span class="sd">"""Initialize the layers and store as self.module_list."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">module_list</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="n">last_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">width</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layers</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">module_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_layer</span><span class="p">,</span> <span class="n">width</span><span class="p">))</span>
      <span class="n">last_layer</span> <span class="o">=</span> <span class="n">width</span>
      <span class="k">if</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_activation</span><span class="p">())</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
    <span class="sd">"""Forward pass; map latent vectors to samples."""</span>
    <span class="n">intermediate</span> <span class="o">=</span> <span class="n">input_tensor</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_list</span><span class="p">:</span>
      <span class="n">intermediate</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">intermediate</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">intermediate</span>


<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">layers</span><span class="p">):</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_init_layers</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_init_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">):</span>
    <span class="sd">"""Initialize the layers and store as self.module_list."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">module_list</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="n">last_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">width</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layers</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">module_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_layer</span><span class="p">,</span> <span class="n">width</span><span class="p">))</span>
      <span class="n">last_layer</span> <span class="o">=</span> <span class="n">width</span>
      <span class="k">if</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">module_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
    <span class="sd">"""Forward pass; map samples to confidence they are real [0, 1]."""</span>
    <span class="n">intermediate</span> <span class="o">=</span> <span class="n">input_tensor</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_list</span><span class="p">:</span>
      <span class="n">intermediate</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">intermediate</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">intermediate</span>


<span class="k">class</span> <span class="nc">VanillaGAN</span><span class="p">():</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">discriminator</span><span class="p">,</span> <span class="n">noise_fn</span><span class="p">,</span> <span class="n">data_fn</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">,</span> <span class="n">lr_d</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">lr_g</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">):</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">generator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">discriminator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">noise_fn</span> <span class="o">=</span> <span class="n">noise_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data_fn</span> <span class="o">=</span> <span class="n">data_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optim_d</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                              <span class="n">lr</span><span class="o">=</span><span class="n">lr_d</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optim_g</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                              <span class="n">lr</span><span class="o">=</span><span class="n">lr_g</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target_ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target_zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_vec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Sample from the generator.</span>
<span class="sd">    """</span>
    <span class="n">num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="k">if</span> <span class="n">num</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">num</span>
    <span class="n">latent_vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_fn</span><span class="p">(</span><span class="n">num</span><span class="p">)</span> <span class="k">if</span> <span class="n">latent_vec</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">latent_vec</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">latent_vec</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">samples</span>

  <span class="k">def</span> <span class="nf">real_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Real Data</span>
<span class="sd">    """</span>
    <span class="n">num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="k">if</span> <span class="n">num</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">num</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_fn</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">samples</span>

  <span class="k">def</span> <span class="nf">train_step_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Train the generator one step and return the loss."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">latent_vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">generated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">latent_vec</span><span class="p">)</span>
    <span class="n">classifications</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">generated</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">classifications</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">target_ones</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optim_g</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">train_step_discriminator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Train the discriminator one step and return the losses."""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># real samples</span>
    <span class="n">real_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">pred_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_samples</span><span class="p">)</span>
    <span class="n">loss_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">pred_real</span><span class="p">,</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">target_ones</span><span class="p">)</span>

    <span class="c1"># generated samples</span>
    <span class="n">latent_vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">fake_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">latent_vec</span><span class="p">)</span>
    <span class="n">pred_fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">fake_samples</span><span class="p">)</span>
    <span class="n">loss_fake</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">pred_fake</span><span class="p">,</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">target_zeros</span><span class="p">)</span>

    <span class="c1"># combine</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_real</span> <span class="o">+</span> <span class="n">loss_fake</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optim_d</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss_real</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">loss_fake</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Train both networks and return the losses."""</span>
    <span class="n">loss_d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step_discriminator</span><span class="p">()</span>
    <span class="n">loss_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step_generator</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss_g</span><span class="p">,</span> <span class="n">loss_d</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">):</span>
  <span class="n">epochs</span> <span class="o">=</span> <span class="mi">30</span>
  <span class="n">batches</span> <span class="o">=</span> <span class="mi">100</span>
  <span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
  <span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
  <span class="n">noise_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
  <span class="n">data_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
  <span class="n">gan</span> <span class="o">=</span> <span class="n">VanillaGAN</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span>
                   <span class="n">discriminator</span><span class="p">,</span>
                   <span class="n">noise_fn</span><span class="p">,</span>
                   <span class="n">data_fn</span><span class="p">,</span>
                   <span class="n">lr_d</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                   <span class="n">lr_g</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">,</span>
                   <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
  <span class="n">loss_g</span><span class="p">,</span> <span class="n">loss_d_real</span><span class="p">,</span> <span class="n">loss_d_fake</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">200</span><span class="p">))</span>
  <span class="n">data_scat</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                         <span class="n">label</span><span class="o">=</span><span class="s1">'Data'</span><span class="p">,</span>
                         <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                         <span class="n">s</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span>
                         <span class="n">c</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
  <span class="n">gan_scat</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span>
                        <span class="n">label</span><span class="o">=</span><span class="s1">'GAN'</span><span class="p">,</span>
                        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                        <span class="n">s</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span>
                        <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">loss_g_running</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">loss_d_real_running</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">loss_d_fake_running</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batches</span><span class="p">):</span>
      <span class="n">lg_</span><span class="p">,</span> <span class="p">(</span><span class="n">ldr_</span><span class="p">,</span> <span class="n">ldf_</span><span class="p">)</span> <span class="o">=</span> <span class="n">gan</span><span class="o">.</span><span class="n">train_step</span><span class="p">()</span>
      <span class="n">loss_g_running</span> <span class="o">+=</span> <span class="n">lg_</span>
      <span class="n">loss_d_real_running</span> <span class="o">+=</span> <span class="n">ldr_</span>
      <span class="n">loss_d_fake_running</span> <span class="o">+=</span> <span class="n">ldf_</span>
    <span class="n">loss_g</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_g_running</span> <span class="o">/</span> <span class="n">batches</span><span class="p">)</span>
    <span class="n">loss_d_real</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_d_real_running</span> <span class="o">/</span> <span class="n">batches</span><span class="p">)</span>
    <span class="n">loss_d_fake</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_d_fake_running</span> <span class="o">/</span> <span class="n">batches</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span><span class="si">}</span><span class="s2">s):"</span>
          <span class="sa">f</span><span class="s2">" G=</span><span class="si">{</span><span class="n">loss_g</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">,"</span>
          <span class="sa">f</span><span class="s2">" Dr=</span><span class="si">{</span><span class="n">loss_d_real</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">,"</span>
          <span class="sa">f</span><span class="s2">" Df=</span><span class="si">{</span><span class="n">loss_d_fake</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">gan_scat</span><span class="o">.</span><span class="n">set_offsets</span><span class="p">(</span><span class="n">gan</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">())</span>
    <span class="n">data_scat</span><span class="o">.</span><span class="n">set_offsets</span><span class="p">(</span><span class="n">gan</span><span class="o">.</span><span class="n">real_data</span><span class="p">())</span>

    <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice in the implementaiton above, we use <code class="docutils literal notranslate"><span class="pre">torch.nn.BCELoss</span></code> to implement the discriminator and generator loss with proper “labels”.
They are actually equivalent to your implementation - do you want to varify this fact?</p>
<div class="section" id="gan-demo">
<h3>GAN demo<a class="headerlink" href="#gan-demo" title="Permalink to this headline">¶</a></h3>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title GAN demo</span>
<span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span>

<span class="c1"># https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html</span>
<span class="n">slider_mean</span> <span class="o">=</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                     <span class="n">step</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">readout_format</span><span class="o">=</span><span class="s1">'.5f'</span><span class="p">,</span>
                                     <span class="n">description</span><span class="o">=</span><span class="s2">"Set Target Mean"</span><span class="p">,</span>
                                     <span class="n">style</span><span class="o">=</span><span class="p">{</span><span class="s1">'description_width'</span><span class="p">:</span> <span class="s1">'initial'</span><span class="p">})</span>
<span class="n">slider_sigma</span> <span class="o">=</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                                      <span class="n">step</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">readout_format</span><span class="o">=</span><span class="s1">'.5f'</span><span class="p">,</span>
                                      <span class="n">description</span><span class="o">=</span><span class="s2">"Set Target Sigma"</span><span class="p">,</span>
                                      <span class="n">style</span><span class="o">=</span><span class="p">{</span><span class="s1">'description_width'</span><span class="p">:</span> <span class="s1">'initial'</span><span class="p">})</span>
<span class="n">button</span> <span class="o">=</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Start Training!"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">on_button_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
  <span class="c1"># Display the message within the output widget.</span>
  <span class="k">with</span> <span class="n">output</span><span class="p">:</span>
    <span class="n">train</span><span class="p">(</span><span class="n">slider_mean</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">slider_sigma</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>

<span class="n">button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_button_clicked</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">slider_mean</span><span class="p">,</span> <span class="n">slider_sigma</span><span class="p">,</span> <span class="n">button</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p>Through this tutorial, we have learned</p>
<ul class="simple">
<li><p>How to implement the training loop of GANs.</p></li>
<li><p>Developed an intuition about the training dynamics of GANs.</p></li>
<li><p>How to implement the training objectives for the generator and discriminator of GANs.</p></li>
<li><p>How are GANs connected to density ratio estimation.</p></li>
</ul>
<p>Next tutorial will cover conditional GANs and ethical issues of DL.</p>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W2D5_GenerativeModels/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<div class="prev-next-bottom">
<a class="left-prev" href="W2D5_Tutorial1.html" id="prev-link" title="previous page">Tutorial 1: Variational Autoencoders (VAEs)</a>
<a class="right-next" href="W2D5_Tutorial3.html" id="next-link" title="next page">Tutorial 3: Conditional GANs and Implications of GAN Technology</a>
</div>
</div>
</div>
<footer class="footer mt-5 mt-md-0">
<div class="container">
<p>
        
          By Neuromatch<br/>
        
            © Copyright 2021.<br/>
</p>
</div>
</footer>
</main>
</div>
</div>
<script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>
</body>
</html>