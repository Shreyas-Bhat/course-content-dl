
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 2: Learning Hyperparameters — Neuromatch Academy: Deep Learning</title>
<link href="../../../_static/css/theme.css" rel="stylesheet"/>
<link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
<script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.jpg" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W1D2_Tutorial3.html" rel="next" title="Tutorial 3: Deep linear neural networks"/>
<link href="W1D2_Tutorial1.html" rel="prev" title="Tutorial 1: Gradient Descent and AutoGrad"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.jpg"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main navigation" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
   Introduction
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  The Basics
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/further_reading.html">
     Suggested further reading (TBD)
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 2: Learning Hyperparameters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_Optimization/chapter_title.html">
   Optimization (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_Optimization/student/W1D4_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_Regularization/chapter_title.html">
   Regularization (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Doing more with fewer parameters
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/chapter_title.html">
   Convnets And Recurrent Neural Networks (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial2.html">
     Tutorial 2: Training loop of CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial3.html">
     Tutorial 3: Introduction to RNNs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ModernConvnets/student/W2D2_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/chapter_title.html">
   Modern Recurrent Neural Networks (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial1.html">
     Tutorial 1: Modeling sequencies and encoding text
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial2.html">
     Tutorial 2: Modern RNNs and their variants
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/student/W2D4_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D5_GenerativeModels/chapter_title.html">
   Generative Models (W2D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial1.html">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial2.html">
     Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Advanced topics
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_UnsupervisedAndSelfSupervisedLearning/student/W3D1_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_BasicReinforcementLearning/student/W3D2_Tutorial1.html">
     Tutorial 1: Introduction to Reinforcement Learning
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_ReinforcementLearningForGames/chapter_title.html">
   Reinforcement Learning For Games (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_ReinforcementLearningForGames/student/W3D3_Tutorial1.html">
     Tutorial 1: Learn to play games with RL
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ContinualLearning/chapter_title.html">
   Continual Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ContinualLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Introduction to Continual Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ContinualLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Out-of-distribution (OOD) Learning
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<div class="dropdown-buttons-trigger">
<button aria-label="Download this page" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fas fa-download"></i></button>
<div class="dropdown-buttons">
<!-- ipynb file if we had a myst markdown file -->
<!-- Download raw file -->
<a class="dropdown-buttons" href="../../../_sources/tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial2.ipynb"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Download source file" type="button">.ipynb</button></a>
<!-- Download PDF via print -->
<button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" id="download-print" onclick="window.print()" title="Print to PDF" type="button">.pdf</button>
</div>
</div>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/NeuromatchAcademy/course-content-dl"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 2: Learning Hyperparameters
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-a-shallow-narrow-linear-neural-network">
   Section 1: A shallow Narrow Linear Neural Network
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-1-a-neural-network-from-scratch">
     Section 1.1: A neural network from scratch
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-shallow-narrow-linear-network">
       Video 1: Shallow Narrow Linear Network
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#analytical-exercise-1-1-loss-gradients">
       Analytical Exercise 1.1: Loss Gradients
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#part-i-calculate-gradients">
         Part i: Calculate gradients
        </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#solution">
         Solution
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-1-implement-simple-narrow-lnn">
       Coding Exercise 1.1: Implement simple narrow LNN
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-2-training-landscape">
     Section 1.2: Training landscape
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-training-landscape">
       Video 2: Training-Landscape
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-and-talk-learning-landscape">
       Think and Talk: Learning Landscape
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-training-landscape-explained">
         Video 3: Training-Landscape Explained
        </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-depth-learning-rate-and-initialization">
   Section 2: Depth, Learning rate, and initialization
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-1-the-effect-of-depth">
     Section 2.1: The effect of depth
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-effect-of-depth">
       Video 4: Effect of Depth
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-1-depth-widget">
       Interactive Demo 2.1: Depth widget
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-effect-of-depth-explained">
         Video 5: Effect of Depth Explained
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-2-choosing-a-learning-rate">
     Section 2.2: Choosing a learning rate
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6-learning-rate">
       Video 6: Learning Rate
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-2-learning-rate-widget">
       Interactive Demo 2.2: Learning rate widget
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7-learning-rate-explained">
         Video 7: Learning Rate Explained
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-3-depth-vs-learning-rate">
     Section 2.3: Depth vs Learning Rate
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8-depth-and-learning-rate-interplay">
       Video 8: Depth and Learning Rate Interplay
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#intective-demo-2-3-depth-and-learning-rate">
       Intective Demo 2.3: Depth and Learning-Rate
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-9-depth-and-learning-rate-interplay-explained">
         Video 9: Depth and Learning Rate Interplay Explained
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-4-initialization-matters">
     Section 2.4: Initialization matters
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-10-initialization-matters">
       Video 10: Initialization Matters
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-11-initialization-matters-explained">
       Video 11: Initialization Matters Explained
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#wrap-up">
   Wrap-up
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-12-wrap-up">
     Video 12: Wrap-up
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#appendix">
   Appendix
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#hyperparameter-interaction">
     Hyperparameter interaction
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial2.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<div class="section" id="tutorial-2-learning-hyperparameters">
<h1>Tutorial 2: Learning Hyperparameters<a class="headerlink" href="#tutorial-2-learning-hyperparameters" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 1, Day 2: Linear Deep Learning</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Andrew Saxe, Saeed Salehi</p>
<p><strong>Content reviewers:</strong> Polina Turishcheva</p>
<p><strong>Content editors:</strong> Anoop Kulkarni</p>
<p><strong>Production editors:</strong> Khalid Almubarak, Spiros Chavlis</p>
<p><strong>Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs</strong></p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p><hr class="docutils"/>
<p>#Tutorial Objectives</p>
<ul class="simple">
<li><p>Training landscape</p></li>
<li><p>The effect of depth</p></li>
<li><p>Choosing a learning rate</p></li>
<li><p>Initialisation matters</p></li>
</ul>
<p>Tutorial slides</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Tutorial slides</span>
<span class="c1"># you should link the slides for all tutorial videos here (we will store pdfs on osf)</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="n">HTML</span><span class="p">(</span><span class="s1">'&lt;iframe src="https://docs.google.com/presentation/d/1ao5fJrxtQTMKaWXWALDtFjHeWFYl25M1btGfsS6TIs0/embed?start=false&amp;loop=false&amp;delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"&gt;&lt;/iframe&gt;'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>This a GPU-Free tutorial!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="c1"># import ipywidgets as widgets</span>
<span class="c1"># from ipywidgets import interact, fixed, HBox, Layout, VBox, interactive, Label</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">IntSlider</span><span class="p">,</span> <span class="n">FloatSlider</span><span class="p">,</span> <span class="n">interact_manual</span><span class="p">,</span> <span class="n">fixed</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">Button</span><span class="p">,</span> <span class="n">HBox</span><span class="p">,</span> <span class="n">interactive_output</span><span class="p">,</span> <span class="n">ToggleButton</span><span class="p">,</span> <span class="n">Layout</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="nn">cm</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.axes_grid1</span> <span class="kn">import</span> <span class="n">make_axes_locatable</span>

<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="o">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s1">'retina'</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Plotting functions</span>

<span class="k">def</span> <span class="nf">plot_x_y_</span><span class="p">(</span><span class="n">x_t_</span><span class="p">,</span> <span class="n">y_t_</span><span class="p">,</span> <span class="n">x_ev_</span><span class="p">,</span> <span class="n">y_ev_</span><span class="p">,</span> <span class="n">loss_log_</span><span class="p">,</span> <span class="n">weight_log_</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  """</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_t_</span><span class="p">,</span> <span class="n">y_t_</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'training data'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_ev_</span><span class="p">,</span> <span class="n">y_ev_</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'test results'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'y'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_log_</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'epochs'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'mean squared error'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">weight_log_</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'epochs'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'weights'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_vector_field</span><span class="p">(</span><span class="n">what</span><span class="p">,</span> <span class="n">init_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  """</span>
  <span class="n">n_epochs</span><span class="o">=</span><span class="mi">40</span>
  <span class="n">lr</span><span class="o">=</span><span class="mf">0.15</span>
  <span class="n">x_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">y_pos</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">x_pos</span>
  <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="o">-</span><span class="mf">1.9</span><span class="p">:</span><span class="mf">2.0</span><span class="p">:</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9</span><span class="p">:</span><span class="mf">2.0</span><span class="p">:</span><span class="mf">0.2</span><span class="p">]</span>
  <span class="n">zz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">xx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">x_temp</span><span class="p">,</span> <span class="n">y_temp</span> <span class="o">=</span> <span class="n">gen_samples</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

  <span class="n">cmap</span> <span class="o">=</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">plasma</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

  <span class="k">if</span> <span class="n">what</span> <span class="o">==</span> <span class="s1">'all'</span> <span class="ow">or</span> <span class="n">what</span> <span class="o">==</span> <span class="s1">'vectors'</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="n">temp_model</span> <span class="o">=</span> <span class="n">ShallowNarrowLNN</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
        <span class="n">da</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="n">temp_model</span><span class="o">.</span><span class="n">dloss_dw</span><span class="p">(</span><span class="n">x_temp</span><span class="p">,</span> <span class="n">y_temp</span><span class="p">)</span>
        <span class="n">zz</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp_model</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">temp_model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_temp</span><span class="p">),</span> <span class="n">y_temp</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">40</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">da</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">db</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="mi">50</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="o">-</span> <span class="n">da</span><span class="p">,</span> <span class="o">-</span> <span class="n">db</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">cmap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">da</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">db</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>

  <span class="k">if</span> <span class="n">what</span> <span class="o">==</span> <span class="s1">'all'</span> <span class="ow">or</span> <span class="n">what</span> <span class="o">==</span> <span class="s1">'trajectory'</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">init_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">init_weights</span> <span class="ow">in</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.55</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.45</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">]]:</span>
        <span class="n">temp_model</span> <span class="o">=</span> <span class="n">ShallowNarrowLNN</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">temp_records</span> <span class="o">=</span> <span class="n">temp_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_temp</span><span class="p">,</span> <span class="n">y_temp</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">temp_records</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">temp_records</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">c</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">temp_records</span><span class="p">)),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'Greys'</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">temp_records</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">temp_records</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">temp_records</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">temp_records</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'X'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">temp_model</span> <span class="o">=</span> <span class="n">ShallowNarrowLNN</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">temp_records</span> <span class="o">=</span> <span class="n">temp_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_temp</span><span class="p">,</span> <span class="n">y_temp</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">temp_records</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">temp_records</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">c</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">temp_records</span><span class="p">)),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'Greys'</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">temp_records</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">temp_records</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">temp_records</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">temp_records</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'X'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">what</span> <span class="o">==</span> <span class="s1">'all'</span> <span class="ow">or</span> <span class="n">what</span> <span class="o">==</span> <span class="s1">'loss'</span><span class="p">:</span>
    <span class="n">contplt</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">zz</span><span class="o">+</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">zorder</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'coolwarm'</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s2">"right"</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s2">"5%"</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contplt</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">'log (Loss)'</span><span class="p">)</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"$w_1$"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"$w_2$"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.9</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.9</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_loss_landscape</span><span class="p">():</span>
  <span class="sd">"""</span>
<span class="sd">  """</span>
  <span class="n">x_temp</span><span class="p">,</span> <span class="n">y_temp</span> <span class="o">=</span> <span class="n">gen_samples</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

  <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="o">-</span><span class="mf">1.9</span><span class="p">:</span><span class="mf">2.0</span><span class="p">:</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9</span><span class="p">:</span><span class="mf">2.0</span><span class="p">:</span><span class="mf">0.2</span><span class="p">]</span>
  <span class="n">zz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">xx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
      <span class="n">temp_model</span> <span class="o">=</span> <span class="n">ShallowNarrowLNN</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
      <span class="n">zz</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp_model</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">temp_model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_temp</span><span class="p">),</span> <span class="n">y_temp</span><span class="p">)</span>

  <span class="n">temp_model</span> <span class="o">=</span> <span class="n">ShallowNarrowLNN</span><span class="p">([</span><span class="o">-</span><span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">])</span>
  <span class="n">loss_rec_1</span><span class="p">,</span> <span class="n">w_rec_1</span> <span class="o">=</span> <span class="n">temp_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_temp</span><span class="p">,</span> <span class="n">y_temp</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mi">240</span><span class="p">)</span>

  <span class="n">temp_model</span> <span class="o">=</span> <span class="n">ShallowNarrowLNN</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">])</span>
  <span class="n">loss_rec_2</span><span class="p">,</span> <span class="n">w_rec_2</span> <span class="o">=</span> <span class="n">temp_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_temp</span><span class="p">,</span> <span class="n">y_temp</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mi">240</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">'3d'</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">zz</span><span class="o">+</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'coolwarm'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter3D</span><span class="p">(</span><span class="n">w_rec_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">w_rec_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">loss_rec_1</span><span class="o">+</span><span class="mf">0.5</span><span class="p">),</span>
                <span class="n">c</span><span class="o">=</span><span class="s1">'k'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter3D</span><span class="p">(</span><span class="n">w_rec_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">w_rec_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">loss_rec_2</span><span class="o">+</span><span class="mf">0.5</span><span class="p">),</span>
                <span class="n">c</span><span class="o">=</span><span class="s1">'k'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">"off"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">260</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">depth_widget</span><span class="p">(</span><span class="n">depth</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">depth</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">depth_lr_init_interplay</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">depth_lr_init_interplay</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">lr_widget</span><span class="p">(</span><span class="n">lr</span><span class="p">):</span>
  <span class="n">depth_lr_init_interplay</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">depth_lr_interplay</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
  <span class="n">depth_lr_init_interplay</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">depth_lr_init_interplay</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">init_weights</span><span class="p">):</span>
  <span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">600</span>

  <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">gen_samples</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">DeepNarrowLNN</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">init_weights</span><span class="p">))</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">),</span>
            <span class="n">linewidth</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'m'</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training a </span><span class="si">{}</span><span class="s2">-layer LNN with"</span>
  <span class="s2">" $\eta=$</span><span class="si">{}</span><span class="s2"> initialized with $w_i=$</span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">init_weights</span><span class="p">),</span> <span class="n">pad</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">'log'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'epochs'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Log mean squared error'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_init_effect</span><span class="p">():</span>
  <span class="n">depth</span> <span class="o">=</span> <span class="mi">15</span>
  <span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">250</span>
  <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.02</span>

  <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">gen_samples</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">init_w</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.09</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">):</span>
      <span class="n">model</span> <span class="o">=</span> <span class="n">DeepNarrowLNN</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">),</span> <span class="n">init_w</span><span class="p">))</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">),</span>
              <span class="n">linewidth</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"initial weights </span><span class="si">{:.2f}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">init_w</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training a </span><span class="si">{}</span><span class="s2">-layer narrow LNN with $\eta=$</span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">lr</span><span class="p">),</span> <span class="n">pad</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">'log'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'epochs'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Log mean squared error'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower left'</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">InterPlay</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">success</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_depth</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">65</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">depth_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">61</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">i_depth</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.105</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">600</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">gen_samples</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">converged</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">button</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">slider</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">init_weights</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">update</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">converged</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">i_depth</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">depth_list</span><span class="p">):</span>
      <span class="n">depth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">i_depth</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">i_depth</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">success</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">converged</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">slider</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="mf">0.005</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">i_depth</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">depth_list</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">description</span> <span class="o">=</span> <span class="s1">'Explore!'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">button_style</span> <span class="o">=</span> <span class="s1">'danger'</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">button_style</span> <span class="o">=</span> <span class="s1">''</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">description</span> <span class="o">=</span> <span class="s1">'Done!'</span>
      <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>

    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">i_depth</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">depth_list</span><span class="p">):</span>
      <span class="n">depth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">i_depth</span><span class="p">]</span>
      <span class="c1"># assert self.min_depth &lt;= depth &lt;= self.max_depth</span>
      <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span> <span class="o">&lt;=</span> <span class="n">lr</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lr</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">converged</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">model</span> <span class="o">=</span> <span class="n">DeepNarrowLNN</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">depth</span><span class="p">),</span> <span class="n">init_weights</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">))</span>
      <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">&lt;</span> <span class="mf">1e-2</span><span class="p">):</span>
        <span class="n">success</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">&lt;</span> <span class="mf">1e-2</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="n">success</span><span class="p">:]</span> <span class="o">&lt;</span> <span class="mf">1e-2</span><span class="p">)):</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">converged</span> <span class="o">=</span> <span class="kc">True</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">success</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">success</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">depth</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">False</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">button_style</span> <span class="o">=</span> <span class="s1">'success'</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">description</span> <span class="o">=</span> <span class="s1">'Register!'</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">button_style</span> <span class="o">=</span> <span class="s1">'danger'</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">description</span> <span class="o">=</span> <span class="s1">'Explore!'</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">button_style</span> <span class="o">=</span> <span class="s1">'danger'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">button</span><span class="o">.</span><span class="n">description</span> <span class="o">=</span> <span class="s1">'Explore!'</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">constrained_layout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">gs</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_gridspec</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">ax3</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'m'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Training a </span><span class="si">{}</span><span class="s2">-layer LNN with"</span>
    <span class="s2">" $\eta=$</span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">lr</span><span class="p">),</span> <span class="n">pad</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">'log'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'epochs'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Log mean squared error'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_depth</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Depth'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Learning time (Epochs)'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Learning time vs depth"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">success</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>

    <span class="c1"># ax3.set_yscale('log')</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_depth</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lr</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Depth'</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Optimial learning rate'</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Empirically optimal $\eta$ vs depth"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Helper functions</span>

<span class="k">def</span> <span class="nf">gen_samples</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">σ</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
  <span class="sd">"""generates `n` samples with `y = z * x + noise(σ)` linear relation. """</span>
  <span class="k">assert</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">0</span>
  <span class="k">assert</span> <span class="n">σ</span> <span class="o">&gt;=</span> <span class="mi">0</span>

  <span class="k">if</span> <span class="n">σ</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span> <span class="o">=</span> <span class="n">σ</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">noise</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span>
  <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>


<span class="k">class</span> <span class="nc">ShallowNarrowLNN</span><span class="p">:</span>
  <span class="sd">"""</span>
<span class="sd">  Shallow and narrow (one neuron per layer) linear neural network</span>
<span class="sd">  """</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_ws</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    init_ws: initial weights as a list</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init_ws</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">init_ws</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">=</span> <span class="n">init_ws</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">=</span> <span class="n">init_ws</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    The forward pass through netwrok y = x * w1 * w2</span>
<span class="sd">    """</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span>
    <span class="k">return</span> <span class="n">y</span>

  <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_p</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Mean squared error (L2) with 1/2 for convenience</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="n">y_p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y_t</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_t</span> <span class="o">-</span> <span class="n">y_p</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">mse</span>

  <span class="k">def</span> <span class="nf">dloss_dw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    partial derivative of loss with respect to weights</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y_t</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">Error</span> <span class="o">=</span> <span class="n">y_t</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">*</span> <span class="n">x</span>
    <span class="n">dloss_dw1</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">Error</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">dloss_dw2</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">Error</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">dloss_dw1</span><span class="p">,</span> <span class="n">dloss_dw2</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">η</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">n_ep</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Gradient descent algorithm</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y_t</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">loss_records</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_ep</span><span class="p">)</span>  <span class="c1"># pre allocation of loss records</span>
    <span class="n">weight_records</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_ep</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>  <span class="c1"># pre allocation of weight records</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_ep</span><span class="p">):</span>
      <span class="n">y_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="n">loss_records</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">y_p</span><span class="p">,</span> <span class="n">y_t</span><span class="p">)</span>
      <span class="n">dloss_dw1</span><span class="p">,</span> <span class="n">dloss_dw2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dloss_dw</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_t</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">-=</span> <span class="n">η</span> <span class="o">*</span> <span class="n">dloss_dw1</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">-=</span> <span class="n">η</span> <span class="o">*</span> <span class="n">dloss_dw2</span>
      <span class="n">weight_records</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">loss_records</span><span class="p">,</span> <span class="n">weight_records</span>


<span class="k">class</span> <span class="nc">DeepNarrowLNN</span><span class="p">:</span>
  <span class="sd">"""</span>
<span class="sd">  Deep but thin (one neuron per layer) linear neural network</span>
<span class="sd">  """</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_ws</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    init_ws: initial weights as a numpy array</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">init_ws</span><span class="o">.</span><span class="n">size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">init_ws</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    x: input features</span>
<span class="sd">    """</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">y</span>

  <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_t</span><span class="p">,</span> <span class="n">y_p</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    mean squared error (L2 loss)</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="n">y_p</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y_t</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_t</span> <span class="o">-</span> <span class="n">y_p</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">mse</span>

  <span class="k">def</span> <span class="nf">dloss_dw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_t</span><span class="p">,</span> <span class="n">y_p</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    analytical gradient of weights</span>
<span class="sd">    """</span>
    <span class="n">E</span> <span class="o">=</span> <span class="n">y_t</span> <span class="o">-</span> <span class="n">y_p</span>  <span class="c1"># = y_t - x * np.prod(self.W)</span>
    <span class="n">Ex</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">E</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">Wp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">+</span> <span class="mf">1e-9</span><span class="p">)</span>
    <span class="n">dW</span> <span class="o">=</span> <span class="o">-</span> <span class="n">Ex</span> <span class="o">*</span> <span class="n">Wp</span>
    <span class="k">return</span> <span class="n">dW</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_t</span><span class="p">,</span> <span class="n">η</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    training using gradient descent</span>
<span class="sd">    """</span>
    <span class="n">loss_records</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
    <span class="n">loss_records</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
      <span class="n">y_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="n">loss_records</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">y_t</span><span class="p">,</span> <span class="n">y_p</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
      <span class="n">dloss_dw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dloss_dw</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_t</span><span class="p">,</span> <span class="n">y_p</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dloss_dw</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">dloss_dw</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">loss_records</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">-=</span> <span class="n">η</span> <span class="o">*</span> <span class="n">dloss_dw</span>
    <span class="k">return</span> <span class="n">loss_records</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline">¶</a></h2>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Set random seed</span>

<span class="c1">#@markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># for DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.'</span><span class="p">)</span>


<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h2>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>

<span class="c1"># inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"WARNING: For this notebook to perform best, "</span>
        <span class="s2">"if possible, in the menu under `Runtime` -&gt; "</span>
        <span class="s2">"`Change runtime type.`  select `GPU` "</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook."</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-a-shallow-narrow-linear-neural-network">
<h1>Section 1: A shallow Narrow Linear Neural Network<a class="headerlink" href="#section-1-a-shallow-narrow-linear-neural-network" title="Permalink to this headline">¶</a></h1>
<div class="section" id="section-1-1-a-neural-network-from-scratch">
<h2>Section 1.1: A neural network from scratch<a class="headerlink" href="#section-1-1-a-neural-network-from-scratch" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-1-shallow-narrow-linear-network">
<h3>Video 1: Shallow Narrow Linear Network<a class="headerlink" href="#video-1-shallow-narrow-linear-network" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
<p>To better understand the behavior of neural network training with gradient descent, we start with the incredibly simple case of a shallow narrow linear neural net, since state-of-the-art models are impossible to dissect and comprehend with our current mathematical tools.</p>
<p>The model we use has one hidden layer, with only one neuron, and two weights. We consider the squared error (or L2 loss) as the cost function. As you may have already guessed, we can visualize the model as a neural network:</p>
<center><img src="https://raw.githubusercontent.com/ssnio/statics/main/neuromatch/shallow_narrow_nn.png" width="400"/></center>
<br/>
<p>or by its computation graph:</p>
<center><img alt="Shallow Narrow Graph" src="https://raw.githubusercontent.com/ssnio/statics/main/neuromatch/shallow_narrow.png" width="400"/></center>
<p>or on a rare occasion, even as a reasonably compact mapping:</p>
<div class="math notranslate nohighlight">
\[ loss = (y - w_1 \cdot w_2 \cdot x)^2 \]</div>
<br/>
</div>
<div class="section" id="analytical-exercise-1-1-loss-gradients">
<h3>Analytical Exercise 1.1: Loss Gradients<a class="headerlink" href="#analytical-exercise-1-1-loss-gradients" title="Permalink to this headline">¶</a></h3>
<div class="section" id="part-i-calculate-gradients">
<h4>Part i: Calculate gradients<a class="headerlink" href="#part-i-calculate-gradients" title="Permalink to this headline">¶</a></h4>
<p>Once again, we ask you to calculate the network gradients analytically, since you will need them for the next exercise. We understand how annoying this is.</p>
<p><span class="math notranslate nohighlight">\(\dfrac{\partial{loss}}{\partial{w_1}} = ?\)</span></p>
<p><span class="math notranslate nohighlight">\(\dfrac{\partial{loss}}{\partial{w_2}} = ?\)</span></p>
<br/>
</div>
<hr class="docutils"/>
<div class="section" id="solution">
<h4>Solution<a class="headerlink" href="#solution" title="Permalink to this headline">¶</a></h4>
<p><span class="math notranslate nohighlight">\(\dfrac{\partial{loss}}{\partial{w_1}} = 2~w_2 \cdot x \cdot (y - w_1 \cdot w_2 \cdot x)\)</span></p>
<p><span class="math notranslate nohighlight">\(\dfrac{\partial{loss}}{\partial{w_2}} = 2~w_1 \cdot x \cdot (y - w_1 \cdot w_2 \cdot x)\)</span></p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="coding-exercise-1-1-implement-simple-narrow-lnn">
<h3>Coding Exercise 1.1: Implement simple narrow LNN<a class="headerlink" href="#coding-exercise-1-1-implement-simple-narrow-lnn" title="Permalink to this headline">¶</a></h3>
<p>Next, we ask you to implement the <code class="docutils literal notranslate"><span class="pre">forward</span></code> pass for our model from scratch without using PyTorch.</p>
<p>Also, although our model gets a single input feature and outputs a single prediction, we could calculate the loss and perform training for multiple samples at once. This is the common practice for neural networks, since computers are incredibly fast doing matrix (or tensor) operations on batches of data, rather than processing samples one at a time through <code class="docutils literal notranslate"><span class="pre">for</span></code> loops. Therefore, for the <code class="docutils literal notranslate"><span class="pre">loss</span></code> function, please implement the <strong>mean</strong> squared error (MSE), and adjust your analytical gradients accordingly when implementing the <code class="docutils literal notranslate"><span class="pre">dloss_dw</span></code> function.</p>
<p>Finally, complete the <code class="docutils literal notranslate"><span class="pre">train</span></code> function for the gradient descent algorithm:</p>
<div class="math notranslate nohighlight">
\[\mathbf{w}^{(t+1)} = \mathbf{w}^{(t)} - \eta \nabla loss (\mathbf{w}^{(t)})\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ShallowNarrowExercise</span><span class="p">:</span>
  <span class="sd">"""Shallow and narrow (one neuron per layer) linear neural network</span>
<span class="sd">  """</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_weights</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Args:</span>
<span class="sd">      init_weights (list): initial weights</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init_weights</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">=</span> <span class="n">init_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">=</span> <span class="n">init_weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>


  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""The forward pass through netwrok y = x * w1 * w2</span>

<span class="sd">    Args:</span>
<span class="sd">      x (np.ndarray): features (inputs) to neural net</span>

<span class="sd">    returns:</span>
<span class="sd">      (np.ndarray): neural network output (prediction)</span>
<span class="sd">    """</span>
    <span class="c1">#################################################</span>
    <span class="c1">## Implement the forward pass to calculate prediction</span>
    <span class="c1">## Note that prediction is not the loss</span>
    <span class="c1"># Complete the function and remove or comment the line below</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Forward Pass `forward`"</span><span class="p">)</span>
    <span class="c1">#################################################</span>
    <span class="n">y</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="n">y</span>


  <span class="k">def</span> <span class="nf">dloss_dw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_true</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="sd">"""Gradient of loss with respect to weights</span>

<span class="sd">    Args:</span>
<span class="sd">      x (np.ndarray): features (inputs) to neural net</span>
<span class="sd">      y_true (np.ndarray): true labels</span>

<span class="sd">    returns:</span>
<span class="sd">      (float): mean gradient of loss with respect to w1</span>
<span class="sd">      (float): mean gradient of loss with respect to w2</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span>
    <span class="c1">#################################################</span>
    <span class="c1">## Implement the gradient computation function</span>
    <span class="c1"># Complete the function and remove or comment the line below</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Gradient of Loss `dloss_dw`"</span><span class="p">)</span>
    <span class="c1">#################################################</span>
    <span class="n">dloss_dw1</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">dloss_dw2</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="n">dloss_dw1</span><span class="p">,</span> <span class="n">dloss_dw2</span>


  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_true</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">n_ep</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">"""Training with Gradient descent algorithm</span>

<span class="sd">    Args:</span>
<span class="sd">      x (np.ndarray): features (inputs) to neural net</span>
<span class="sd">      y_true (np.ndarray): true labels</span>
<span class="sd">      lr (float): learning rate</span>
<span class="sd">      n_ep (int): number of epochs (training iterations)</span>

<span class="sd">    returns:</span>
<span class="sd">      (list): training loss records</span>
<span class="sd">      (list): training weight records (evolution of weights)</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">loss_records</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_ep</span><span class="p">)</span>  <span class="c1"># pre allocation of loss records</span>
    <span class="n">weight_records</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_ep</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>  <span class="c1"># pre allocation of weight records</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_ep</span><span class="p">):</span>
      <span class="n">y_prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="n">loss_records</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">y_prediction</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
      <span class="n">dloss_dw1</span><span class="p">,</span> <span class="n">dloss_dw2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dloss_dw</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
      <span class="c1">#################################################</span>
      <span class="c1">## Implement the gradient descent step</span>
      <span class="c1"># Complete the function and remove or comment the line below</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Training loop `train`"</span><span class="p">)</span>
      <span class="c1">#################################################</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">-=</span> <span class="o">...</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">-=</span> <span class="o">...</span>
      <span class="n">weight_records</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">loss_records</span><span class="p">,</span> <span class="n">weight_records</span>


<span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">y_prediction</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_true</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
  <span class="sd">"""Mean squared error</span>

<span class="sd">  Args:</span>
<span class="sd">    y_prediction (np.ndarray): model output (prediction)</span>
<span class="sd">    y_true (np.ndarray): true label</span>

<span class="sd">  returns:</span>
<span class="sd">    (np.ndarray): mean squared error loss</span>
<span class="sd">  """</span>
  <span class="k">assert</span> <span class="n">y_prediction</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span>
  <span class="c1">#################################################</span>
  <span class="c1">## Implement the MEAN squared error</span>
  <span class="c1"># Complete the function and remove or comment the line below</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Loss function `loss`"</span><span class="p">)</span>
  <span class="c1">#################################################</span>
  <span class="n">mse</span> <span class="o">=</span> <span class="o">...</span>
  <span class="k">return</span> <span class="n">mse</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">211</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">initial_weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6</span><span class="p">]</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">gen_samples</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">73</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">σ</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">x_eval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1">## Uncomment to run</span>
<span class="c1"># sn_model = ShallowNarrowExercise(initial_weights)</span>
<span class="c1"># loss_log, weight_log = sn_model.train(x_train, y_train, learning_rate, n_epochs)</span>
<span class="c1"># y_eval = sn_model.forward(x_eval)</span>

<span class="c1"># plot_x_y_(x_train, y_train, x_eval, y_eval, loss_log, weight_log)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D2_LinearDeepLearning/solutions/W1D2_Tutorial2_Solution_257083f2.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D2_LinearDeepLearning/static/W1D2_Tutorial2_Solution_257083f2_1.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D2_LinearDeepLearning/static/W1D2_Tutorial2_Solution_257083f2_1.png" style="width: 1696.0px; height: 544.0px;"/></a>
</div>
</div>
<div class="section" id="section-1-2-training-landscape">
<h2>Section 1.2: Training landscape<a class="headerlink" href="#section-1-2-training-landscape" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-2-training-landscape">
<h3>Video 2: Training-Landscape<a class="headerlink" href="#video-2-training-landscape" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
<p>As you may have already asked yourself, we can analytically find <span class="math notranslate nohighlight">\(w_1\)</span> and <span class="math notranslate nohighlight">\(w_2\)</span> without using gradient descent:</p>
<div class="math notranslate nohighlight">
\[w_1 \cdot w_2 = \dfrac{y}{x} \]</div>
<p>In fact, we can plot the gradients, the loss function and all the possible solutions in one figure. In this example, we use the <span class="math notranslate nohighlight">\(y = 1x\)</span> mapping:</p>
<p><strong>Blue ribbon</strong>: shows all possible solutions: <span class="math notranslate nohighlight">\(~ w_1 w_2 = \dfrac{y}{x} = \dfrac{x}{x} = 1 \Rightarrow w_1 = \dfrac{1}{w_2}\)</span></p>
<p><strong>Contour background</strong>: Shows the loss values, red being higher loss</p>
<p><strong>Vector field (arrows)</strong>: shows the gradient vector field. The larger yellow arrows show larger gradients, which correspond to bigger steps by gradient descent.</p>
<p><strong>Scatter circles</strong>: the trajectory (evolution) of weights during training for three different initializations, with blue dots marking the start of training and red crosses ( <strong>x</strong> ) marking the end of training. You can also try your own initializations (keep the initial values between <code class="docutils literal notranslate"><span class="pre">-2.0</span></code> and <code class="docutils literal notranslate"><span class="pre">2.0</span></code>) as shown here:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot_vector_field</span><span class="p">(</span><span class="s1">'all'</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">])</span>
</pre></div>
</div>
<p>Finally, if the plot is too crowded, feel free to pass one of the following strings as argument:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot_vector_field</span><span class="p">(</span><span class="s1">'vectors'</span><span class="p">)</span>  <span class="c1"># for vector field</span>
<span class="n">plot_vector_field</span><span class="p">(</span><span class="s1">'trajectory'</span><span class="p">)</span>  <span class="c1"># for training trajectory</span>
<span class="n">plot_vector_field</span><span class="p">(</span><span class="s1">'loss'</span><span class="p">)</span>  <span class="c1"># for loss contour</span>
</pre></div>
</div>
</div>
<div class="section" id="think-and-talk-learning-landscape">
<h3>Think and Talk: Learning Landscape<a class="headerlink" href="#think-and-talk-learning-landscape" title="Permalink to this headline">¶</a></h3>
<p>Explore the next two plots. Try different initial values.  Can you find the saddle point? Why does training slow down near the minima? Discuss your findings with your pod.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot_vector_field</span><span class="p">(</span><span class="s1">'all'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here, we also visualize the loss landscape in a 3-D plot, with two training trajectories for different initial conditions.
Note: the trajectories from the 3D plot and the previous plot are independent and different.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot_loss_landscape</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="video-3-training-landscape-explained">
<h4>Video 3: Training-Landscape Explained<a class="headerlink" href="#video-3-training-landscape-explained" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-depth-learning-rate-and-initialization">
<h1>Section 2: Depth, Learning rate, and initialization<a class="headerlink" href="#section-2-depth-learning-rate-and-initialization" title="Permalink to this headline">¶</a></h1>
<p>Successful deep learning models are often developed by a team of very clever people, spending many many hours “tuning” learning hyperparameters, and finding effective initializations. In this section, we look at three basic (but often not simple) hyperparameters: depth, learning rate, and initialization.</p>
<div class="section" id="section-2-1-the-effect-of-depth">
<h2>Section 2.1: The effect of depth<a class="headerlink" href="#section-2-1-the-effect-of-depth" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-4-effect-of-depth">
<h3>Video 4: Effect of Depth<a class="headerlink" href="#video-4-effect-of-depth" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
<p>In 1989, George Cybenko published the paper <em>Approximation by superpositions of a sigmoidal function</em>, mathematically proving that:</p>
<blockquote>
<div><p>arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity.</p>
</div></blockquote>
<p>So if a neural net with a single hidden layer can approximate any function, why might depth be useful? What makes a network or learning system “deep”? The reality is that shallow neural nets are often incapable of learning complex functions due to data limitations. On the other hand, depth seems like magic. Depth can change the functions a network can represent, the way a network learns, and how a network generalizes to unseen data.</p>
<p>So let’s look at the challenges that depth poses in training a neural network. Imagine a single input, single output linear network with 50 hidden layers and only one neuron per layer (i.e. a narrow deep neural network). The output of the network is easy to calculate:</p>
<div class="math notranslate nohighlight">
\[ prediction = x \cdot w_1 \cdot w_2 \cdot \cdot \cdot w_{50} \]</div>
<p>If the initial value for all the weights is <span class="math notranslate nohighlight">\(w_i = 2\)</span>, the prediction for <span class="math notranslate nohighlight">\(x=1\)</span> would be <strong>exploding</strong>: <span class="math notranslate nohighlight">\(y_p = 2^{50} \approx 1.1256 \times 10^{15}\)</span>. On the other hand, for weights initialized to <span class="math notranslate nohighlight">\(w_i = 0.5\)</span>, the output is <strong>vanishing</strong>: <span class="math notranslate nohighlight">\(y_p = 0.5^{50} \approx 8.88 \times 10^{-16}\)</span>. Similarly, if we recall the chain rule, as the graph gets deeper, the number of elements in the chain multiplication increases, which could lead to exploding or vanishing gradients. To avoid such numerical vulnerablities that could impair our training algorithm, we need to understand the effect of depth.</p>
</div>
<div class="section" id="interactive-demo-2-1-depth-widget">
<h3>Interactive Demo 2.1: Depth widget<a class="headerlink" href="#interactive-demo-2-1-depth-widget" title="Permalink to this headline">¶</a></h3>
<p>Use the widget to explore the impact of depth on the training curve (loss evolution) of a deep but narrow neural network and discuss your findings with your pod. More specifically, try answering the following questions.</p>
<p><strong>Questions</strong>:
Which networks trained the fastest? Did all networks eventually “work” (converge)? What is the shape of their learning trajectory?</p>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">interact</span><span class="p">(</span><span class="n">depth_widget</span><span class="p">,</span>
    <span class="n">depth</span> <span class="o">=</span> <span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">51</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="video-5-effect-of-depth-explained">
<h4>Video 5: Effect of Depth Explained<a class="headerlink" href="#video-5-effect-of-depth-explained" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
</div>
<div class="section" id="section-2-2-choosing-a-learning-rate">
<h2>Section 2.2: Choosing a learning rate<a class="headerlink" href="#section-2-2-choosing-a-learning-rate" title="Permalink to this headline">¶</a></h2>
<p>The learning rate is a common hyperparameter for most optimization algorithms. How should we set it? Sometimes the only option is to try all the possibilities, but sometimes knowing some key trade-offs will help guide our search for good hyperparameters.</p>
<div class="section" id="video-6-learning-rate">
<h3>Video 6: Learning Rate<a class="headerlink" href="#video-6-learning-rate" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</div>
<div class="section" id="interactive-demo-2-2-learning-rate-widget">
<h3>Interactive Demo 2.2: Learning rate widget<a class="headerlink" href="#interactive-demo-2-2-learning-rate-widget" title="Permalink to this headline">¶</a></h3>
<p>Here, we fix the network depth to 50 layers. Use the widget to explore the impact of learning rate <span class="math notranslate nohighlight">\(\eta\)</span> on the training curve (loss evolution) of a deep but narrow neural network and discuss your findings with your pod. More specifically, try answering the following questions.</p>
<p><strong>Questions</strong>:
Can we say that larger learning rates always lead to faster learning? Why not?</p>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">interact</span><span class="p">(</span><span class="n">lr_widget</span><span class="p">,</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.045</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span>
                     <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">readout_format</span><span class="o">=</span><span class="s1">'.3f'</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'η'</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="video-7-learning-rate-explained">
<h4>Video 7: Learning Rate Explained<a class="headerlink" href="#video-7-learning-rate-explained" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
</div>
<div class="section" id="section-2-3-depth-vs-learning-rate">
<h2>Section 2.3: Depth vs Learning Rate<a class="headerlink" href="#section-2-3-depth-vs-learning-rate" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-8-depth-and-learning-rate-interplay">
<h3>Video 8: Depth and Learning Rate Interplay<a class="headerlink" href="#video-8-depth-and-learning-rate-interplay" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</div>
<div class="section" id="intective-demo-2-3-depth-and-learning-rate">
<h3>Intective Demo 2.3: Depth and Learning-Rate<a class="headerlink" href="#intective-demo-2-3-depth-and-learning-rate" title="Permalink to this headline">¶</a></h3>
<p><strong>Important instruction</strong>
The exercise starts with 10 hidden layers. Your task is to find the learning rate that delivers fast but robust convergence (learning). When you are confident about the learning rate, you can <strong>Register</strong> the optimal learning rate for the given depth. Once you press register, a deeper model is instantiated, so you can find the next optimal learning rate. The Register button turns green only when the training converges, but does not imply the fastest convergence. Finally, Be patient :-) the widgets are slow.</p>
<p>Discuss your findings with your pod. More specifically, try answering the following questions.</p>
<p><strong>Questions</strong>: Can you explain the relationship between the depth and optimal learning rate?</p>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>
<span class="n">intpl_obj</span> <span class="o">=</span> <span class="n">InterPlay</span><span class="p">()</span>

<span class="n">intpl_obj</span><span class="o">.</span><span class="n">slider</span> <span class="o">=</span> <span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.105</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span>
                               <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'500px'</span><span class="p">),</span>
                               <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                               <span class="n">readout_format</span><span class="o">=</span><span class="s1">'.3f'</span><span class="p">,</span>
                               <span class="n">description</span><span class="o">=</span><span class="s1">'η'</span><span class="p">)</span>

<span class="n">intpl_obj</span><span class="o">.</span><span class="n">button</span> <span class="o">=</span> <span class="n">ToggleButton</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">intpl_obj</span><span class="o">.</span><span class="n">converged</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'Register'</span><span class="p">)</span>

<span class="n">widgets_ui</span> <span class="o">=</span> <span class="n">HBox</span><span class="p">([</span><span class="n">intpl_obj</span><span class="o">.</span><span class="n">slider</span><span class="p">,</span> <span class="n">intpl_obj</span><span class="o">.</span><span class="n">button</span><span class="p">])</span>
<span class="n">widgets_out</span> <span class="o">=</span> <span class="n">interactive_output</span><span class="p">(</span><span class="n">intpl_obj</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                                 <span class="p">{</span><span class="s1">'lr'</span><span class="p">:</span> <span class="n">intpl_obj</span><span class="o">.</span><span class="n">slider</span><span class="p">,</span>
                                  <span class="s1">'update'</span><span class="p">:</span> <span class="n">intpl_obj</span><span class="o">.</span><span class="n">button</span><span class="p">,</span>
                                  <span class="s1">'init_weights'</span><span class="p">:</span> <span class="n">fixed</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)})</span>

<span class="n">display</span><span class="p">(</span><span class="n">widgets_ui</span><span class="p">,</span> <span class="n">widgets_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="video-9-depth-and-learning-rate-interplay-explained">
<h4>Video 9: Depth and Learning Rate Interplay Explained<a class="headerlink" href="#video-9-depth-and-learning-rate-interplay-explained" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
</div>
<div class="section" id="section-2-4-initialization-matters">
<h2>Section 2.4: Initialization matters<a class="headerlink" href="#section-2-4-initialization-matters" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-10-initialization-matters">
<h3>Video 10: Initialization Matters<a class="headerlink" href="#video-10-initialization-matters" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
<p>We’ve seen, even in the simplest of cases, that depth can slow learning. Why? From the chain rule, gradients are multiplied by the current weight at each layer, so the product can vanish or explode. Therefore, weight initialization is a fundamentally important hyperparameter.</p>
<p>Although in practice initial values for learnable parameters are often sampled from different <span class="math notranslate nohighlight">\(\mathcal{Uniform}\)</span> or <span class="math notranslate nohighlight">\(\mathcal{Normal}\)</span> probability distribution, here we use a single value for all the parameters.</p>
<p>The figure below shows the effect of initialization on the speed of learning for the deep but narrow LNN. We have excluded initializations that lead to numerical errors such as <code class="docutils literal notranslate"><span class="pre">nan</span></code> or <code class="docutils literal notranslate"><span class="pre">inf</span></code>, which are the consequence of smaller or larger initializations.</p>
<p>Make sure you execute this cell to see the figure!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Make sure you execute this cell to see the figure!</span>

<span class="n">plot_init_effect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="video-11-initialization-matters-explained">
<h3>Video 11: Initialization Matters Explained<a class="headerlink" href="#video-11-initialization-matters-explained" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="wrap-up">
<h1>Wrap-up<a class="headerlink" href="#wrap-up" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-12-wrap-up">
<h2>Video 12: Wrap-up<a class="headerlink" href="#video-12-wrap-up" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="appendix">
<h1>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">¶</a></h1>
<div class="section" id="hyperparameter-interaction">
<h2>Hyperparameter interaction<a class="headerlink" href="#hyperparameter-interaction" title="Permalink to this headline">¶</a></h2>
<p>Finally, let’s put everything we learned together and find best initial weight and learning rate for a given depth. By now you should have learned the interactions and know how to find the optimal values quickly. If you get <code class="docutils literal notranslate"><span class="pre">numerical</span> <span class="pre">overflow</span></code> warnings, don’t be discouraged! They are often caused by “exploding” or “vanishing” gradients.</p>
<p><strong>Questions</strong>: Did you experience any surprising behaviour or difficulty finding the optimal parameters?</p>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">interact</span><span class="p">(</span><span class="n">depth_lr_init_interplay</span><span class="p">,</span>
             <span class="n">depth</span> <span class="o">=</span> <span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">51</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
             <span class="n">lr</span> <span class="o">=</span> <span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span>
                     <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">readout_format</span><span class="o">=</span><span class="s1">'.3f'</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'η'</span><span class="p">),</span>
             <span class="n">init_weights</span> <span class="o">=</span> <span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                     <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">readout_format</span><span class="o">=</span><span class="s1">'.3f'</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'initial weights'</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W1D2_LinearDeepLearning/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<div class="prev-next-bottom">
<a class="left-prev" href="W1D2_Tutorial1.html" id="prev-link" title="previous page">Tutorial 1: Gradient Descent and AutoGrad</a>
<a class="right-next" href="W1D2_Tutorial3.html" id="next-link" title="next page">Tutorial 3: Deep linear neural networks</a>
</div>
</div>
</div>
<footer class="footer mt-5 mt-md-0">
<div class="container">
<p>
        
          By Neuromatch<br/>
        
            © Copyright 2021.<br/>
</p>
</div>
</footer>
</main>
</div>
</div>
<script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>
</body>
</html>